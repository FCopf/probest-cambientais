# Amostrando uma População Estatística {#amostrmedias}

```{r}
#knitr::opts_chunk$set(echo = FALSE, include = FALSE)
```


O objetivo da amostragem é descrever características da **população estatística** por meio de características da **amostra**. E um estudo sobre o diâmetro dos caules de *Rhizophora mangle* em um manguezal (DAP: diâmetro a altura do peito), a população estatística são os diâmetros de todas as árvores do referido manguezal. A população estatística pode ser descrita por **parâmetros** que representam medidas de centro como o diâmetro médio ($\mu$), ou por medidas de variação como o desvio padrão ($\sigma$), que representam o grau de dispersão das unidades amostrais ao redor da média. Se amostramos **n** elementos desta população, a média amostral ($\overline{X}$) e o desvio padrão amostral ($s$) dos diâmetros serão os estimadores destas características.

Dependendo da questão envolvida e do conhecimento prévio sobre a população, diferentes métodos de amostragem são apropriados. A  **teoria da amostragem** é a área da ciência que estuda estes métodos. Neste capítulo vamos discutir três tipos de amostragem: **aleatória simples**, **estratificada** e **sistemática**.

## Amostragem aleatória simples

É aquela em que cada elemento da população tem a mesma probabilidade de ser selecionado para compor a amostra. Por exemplo, se a população consiste de 1000 elementos, cada um terá uma probabilidade de $\frac{1}{1000}$ de ser escolhido. Isto isenta o pesquisador de tomar qualquer decisão com base em julgamentos pré-concebidos, sobre quais alementos devem ou não compor a amostra.

Para exemplificar suponha uma população hipotética de somente 10 elementos: 

```{r, echo=FALSE}
set.seed(1)
pop = c(3, 10, 14, 19, 27, 28, 29, 41, 42, 43)
Am1 = sort(pop)[1:5]
set.seed(2)
Am2 = sample(pop, size = 5, replace = F)
```

**População**: `r pop`

Em uma amostra aleatória simples de cinco elementos, qualquer combinação destes 10 elementos é **igualmente provável**. Se por puro acaso sortearmos uma amostra aleatória contendo os cinco menores valores da população:

**Amostra 1**: `r  Am1`

A amostra seria **tão aleatória** é válida do ponto de vista amostral quanto qualquer outra como:

**Amostra 2**: `r  Am2`

Isto significa que uma amostra aleatória pode não ser **necessariamente** representativa da população. Amostras pequenas por exemplo, têm uma chance maior de selecionar apenas valores extremos, ou seja, os maiores ou menores elementos da população. A média amostral ($\bar{X}$) calculada para estas amostras estará distante da média populacional ($\mu$). 
No entanto, a importância central da amostragem aleatória em estatística está no fato de que a aleatoriedade produz, **em média**, amostras representativas da população. Deste modo, é esperado que na maioria das vezes, uma amostra aleatória gere médias amostrais próximas à média populacional. Por este motivo, é fundamental prezar pela aleatoriedade no processo amostral, pois de outro modo não poderemos garantir que a inferência seja válida com base nas leis de probabilidade. 

O modo mais direto de se obter uma amostra aleatória é por meio de sorteio. Após atribuir números de 1 a $N$ a cada unidade amostral, estas unidades são sorteadas até que seja atingido o tamanho $n$ desejado. Na prática, nem sempre é possível obtermos uma amostra aleatória nestes moldes. Para o exemplo do DAP de *Rhizophora mangle*, não seria viável primeiramente enumerar todas as árvores para, após um sorteio, tomar as medidas somente das árvores que foram selecionadas. Entretanto, se tivermos as coordenadas geográficas da área, poderíamos sortear $n$ posições no espaço e, chegando ao local desejado, escolher a árvore mais próxima da coordenada sorteada. Este procedimento nos daria um resultado igualmente válido, no sentido de garantir uma escolha aleatória das unidades amostrais. Outras dificuldades práticas obviamente seriam possíveis neste procedimento, como garantir acesso irrestrito à toda a área ou tempo disponível para percorrer a toda região. Questões como estas não desmerecem o requisito básico de se obter uma amostra aleatória, mas nos auxiliam a decidir como conciliar a prática experimental com a necessidade da aleatorização em um experimento.

## Amostragem aleatória estratificada

Se tivermos algum conhecimento prévio de como a população está estruturada, a amostra aleatória simples, embora não esteja incorreta, pode não ser a estratégia mais eficiente. Se for possivel identificar **estratos** ou **subgrupos** dentro da população, podemos conduzir uma **amostragem aleatória estatificada**. 

Voltemos ao exemplo da *Rhizophora mangle*. Suponha que o manguezal em estudo possa ser dividido em duas áreas. Uma área que foi recentemente perturbada por ações antrópicas e encontra-se em estado de regeneração, e uma área que sempre esteve livre da ação humana. Espera-se que as árvores na área íntegra sejam mais velhas e portanto tenham em média DAPs maiores, enquanto na área em regeneração os DAPs médios sejam menores.

Em uma amostra aleatória simples, sobretudo se for pequena, é possível que puramente ao acaso, um ou outro estrato se torne mais representado. Isto tornará as estimativas mais variáveis. Se dermos azar da maioria das unidades amostrais serem sorteadas do estrato íntegro, teremos estimativas de DAP muito acima de $\mu$. No entanto, se a seleção dos indivíduos foi feita por meio de sorteio, o simples fato de observarmos este padrão não é por si só justificativa para refarzermos a amostra. O ponto relevante aqui é que em uma amostra aleatória simples estes extremos indesejáveis são mais prováveis de acontecer.

Em uma amostragem estratificada o esforço amostral é subdividito entre os estratos, que em nosso exemplo seriam as áreas integra e perturbada. O tamanho amostral em cada estrato será o mesmo, ou **proporcional** ao tamanho do estrato. Após definirmos o tamanho amostral em cada estrato, as unidades amostrais são selecionadas por meio de uma amostragem aleatória simples. Deste modo, teremos certeza de que **todos** os estratos estarão representados na amostra conforme sua representatividade na população e as estimativas tenderão a se concentrar mais próximas à $\mu$ se compararmos com os resultados de uma amostra aleatória simples.

Quando os estratos são identificados **corretamente**, a principal vantagem da amostra aleatória estratificada sobre a amostra aleatória simples está em aumentar a **precisão** das estimativas. Mais a frente iremos discutir os conceitos de precisão e acurácia e relacioná-los com as estratégias amostrais discutidas aqui.

## Amostragem sistemática

Uma amostragem sistemática é possível quando as unidades amostrais podem ser ordenadas. A ordenação segue alguma característica da unidade como peso, idade, salinidade, posição no espaço ou intervalo de tempo. O objetivo é garantir que a amostra inclua todo o intervalo de variação da população. Neste tipo de amostragem, selecionamos um elemento inicial e, em intervalos regulares, selecionamos os demais elementos.

Em nossa amostragem de *Rhizophora mangle*, poderíamos ordenar as árvores da menor para a maior, selecionar uma árvore inicial (p. ex. a $5^a$) e um intervalo (por exemplo a cada 10 árvores). A amostragem iria consistir da $5^a$, $15^a$, $25^a$, $35^a$, $\cdots$ árvores, até chegarmos ao maior indivíduo. Deste modo, saberíamos que todo o intervalo de DAPs estaria representado na amostra. Obviamente este exemplo é inviável, pois necessitaríamos de uma lista de **prévia** do tamanho e posição de todas as árvores antes de conduzirmos a amostragem. Um exemplo de amostragem sistemática mais factível, seria definir alguns transectos lineares e dispor $n$ pontos equidistantes. A amostra iria consistir dos DAPs mensurados nas árvores imediatamente mais próximas a cada um dos pontos. Se o comprimento e direção dos transectos forem bem escolhidos, garantimos que toda a área de estudo seja abrangida. Neste caso, o protocolo de amostragem não visou exatamente atingir todos os comprimentos, mas permitir um acesso mais homogêneo a toda a àrea de distribuição dos indivíduos, **assumindo** que de alguma forma, isto também nos permita acessar toda a variação de tamanho dos indivíduos presentes na região.

```{r fig.cap = "Representação de uma área com árvores de tamanhos médios agregados. (B): Em uma amostragem aleatória de com n pequeno, corremos maior risco de termos uma distribuição não representativa das unidades amostrais. (C): A amostragem estratificada resolve este problema uma vez que pois todos os blocos ou estratos serão necessariamente representados na amostra. (C): Uma vez bem definida, a amostragem ssitematica também possibilita a representatividade das unidades amostrais ao longo de todo o intervalo de variação.", fig.align='center', echo=FALSE}
estrat <- image_read_pdf("figs/Apostila_Estatistica_BICT-estrat1.pdf", density = 72)
grid.arrange(rasterGrob(estrat), nrow = 1, ncol = 1)
```

A escolha da amostragem sistemática ao invés de uma amostragem aleatória simples, se deve à sua praticidade. Se a característica de interesse das unidades amostrais estiver disposta de forma aleatória ao longo do transecto escolhido, os dois métodos irão gerar resultados similares. Na maioria dos casos, é isto que o pesquisador assume (ainda que implicitamente) quando opta por uma amostragem sistemática. Por outro lado, se houver um gradiente justamente na direção do transecto, a variância amostral irá **superestimar** a variância populacional equanto, se houver uma periodicidade que coincida com o intervalo escolhido, a variância amostral irá **subestimar** a variância populacional.


## Erro amostral, acurácia e precisão

Como as estimativas são obtidas de um subconjunto da população (a amostra), é regra que o resultado obtido de uma amostra aleatória particular, não será igual ao verdadeiro valor da população (o parâmetro), embora exista uma grande probabilidade estar próximo. O **erro amostral** é a diferença entre uma estimativa em particular e a média populacional e portanto, é inerente à variabilidade do processo de amostragem. Suponha que, puramente ao acaso, a amostra inclua os menores elementos da população. A média amostral ($\overline{X}$) estará abaixo da média populacional ($\mu$) e o erro amostral será grande. O erro amostral é dado por $E = \overline{X} - \mu$. A estatística estuda o comportamento probabilístico dos erros amostrais. Existe também o **erro não amostral** que decorre de equívocos de amostragem, inexperiência do amostrador, falha de equipamentos, enganos no cômputo dos resultados, etc. A estatística não é capaz de lidar com estes erros.

**Acurácia** se refere à proximidade entre o parâmetro e a estimativa **média**. Um estimativa acurada será, em média, igual ao parâmetro populacional. Diferente do erro amostral, a acurácia não se refere a uma estimativa em particular, mas ao valor **esperado** da estimativa, caso a amostragem fosse repetida um grande número de vezes. 
Uma estimativa não-acurada (**viciada**) resulta em valores **consistentemente** diferentes do parâmetro, podendo estar acima (**viés positivo**) ou abaixo (**viés negativo**) do verdadeiro valor populacional. Uma estimativa viciada pode resultar de um processo amostral equivocado ou do uso de um estimador não apropriado.

**Precisão** tem relação com a variabilidade da estimativa. Estimadores que geram estimativas similares entre si são precisos. Porém, se as estimativas estiverem distantes de sua média, o estimador será pouco preciso. Já dissemos que uma amostragem aleatória estratificada, se conduzida corretamente, irá produzir estimativas mais precisas que uma amostra aleatória simples.

O objetivo da amostragem é obter estimativas precisas e acuradas. Porém, na impossibilidade de obtermos um censo, os parâmetros da população jamais serão conhecidos, de modo que é muito difícil termos uma ideia do grau de acurácia de nossas estimativas. Esta questão é conhacida como o *paradoxo da amostragem*:

> *O paradoxo central da amostragem* é que é impossível saber, a partir da observação da amostra, se ela é ou não uma boa amostra, no sentido de que seja livre de viés [@stuart1984ideas]".

```{r fig.cap = "Representação dos conceitos de precisão e acurácia.", fig.align='center', echo=FALSE}
precacu <- image_read_pdf("figs/Precisao-Acuracia-eps-converted-to.pdf", density = 72)
grid.arrange(rasterGrob(precacu), nrow = 1, ncol = 1)
```

### Erro amostral

Voltemos à nossa população fictícia com somente 10 elementos:

**Populaçao**: `r pop`

Para esta população em particular nós conhecemos a média populacional ($\mu$ = `r round(mean(pop),1)`), de modo que será possível compará-la com as estimativas amostrais.
```{r, echo=FALSE}
set.seed(4)
n = 5
Am1 = sample(pop, size = n, replace = F)
somaAm1 = paste(Am1, collapse = "+")
mp = round(mean(pop),1)
mAm1 = round(mean(Am1),1)
E1 = mAm1 - mp
```

O que acontece se tomarmos uma amostra aleatória de tamanho $n = `r n`$:

**Amostra 1**: `r  Am1`

Para esta amostra, a média vale: $\overline{X} =\frac{`r somaAm1`}{`r n`} = `r mAm1`$.

Os valores $\mu = `r mp`$ e $\overline{X} = `r mAm1`$ não são idênticos, pois a amostra contém somente alguns elementos da população. A diferença entre $\mu$ e $\overline{X}$ é o chamamos de **erro amostral**.

Neste caso, o erro amostral é:

**Erro amostral 1**: $E_1 = `r mAm1`  -  `r mp`  =  `r E1`$

Se tomarmos outra amostra aleatória, teremos outro conjunto de unidades amostrais, e consequentemente, um $\overline{X}$ e um erro amostral diferentes. Por exemplo:

```{r, echo=FALSE}
set.seed(3)
n = 5
Am2 = sample(pop, size = n, replace = F)
mAm2 = round(mean(Am2),1)
E2 = mAm2 - mp
```


**Amostra 2**: $`r Am2`$

**Média amostral 2**: $\overline{X_2} = `r mAm2`$

**Erro amostral 2**: $E_2 = `r mAm2`  -  `r mp`  =  `r E2`$


### Acurácia

```{r, echo=FALSE}
N = length(pop)
n = 5
CT = choose(N,n)
```


Até agora, analisamos duas amostras diferentes da população. Porém, quantas amostras distintas seriam possíveis? Para uma população com `r N` elementos, a teoria combinatória nos diz que são possíveis:  

$${{`r N`}\choose{`r 5`}} \frac{`r N`!}{(`r N`-`r n`)! \times `r n`!} = `r CT`$$

formas diferentes de combinarmos $N = `r N`$ elementos em amostras de tamanho $n = `r n`$.

```{r, echo=FALSE}
set.seed(8)
R = 8
A15 = replicate(n = R, sample(pop, size = n, replace = F))
colnames(A15) = paste("A", 1:ncol(A15), sep = " ")
Medias = round(apply(A15, 2, mean),2)
A15 = rbind(A15, Medias)
#A15 = as.data.frame(A15)
```


Inicialmente vamos avaliar a questão com um número menor. Sejam por exemplo, `r R` amostras tomadas aleatoriamente, gerando os resultados a seguir:

```{r, echo=FALSE, warning=FALSE}
#A15
kable(A15)
```

Cada coluna desta matriz corresponde a uma possível amostra aleatória e suas respectivas médias.

Algumas amostras tiveram médias muito distantes de $\mu$, como: $\overline{X_{`r which.max(A15["Medias",])`}} = `r max(A15["Medias",])`$ ou $\overline{X_{`r which.min(A15["Medias",])`}} = `r min(A15["Medias",])`$. Esta variação é natural do processo amostral. Os métodos de amostragem e de inferência estatística tratam justamente de como lidar e interpretar esta variação. Para entender melhor este processo, vamos obter **todas** as `r CT` combinações possíveis de amostras com $n = `r n`$ e, em seguida, extrair suas respectivas médias. 

Os resultados das `r CT` médias possíveis podem ser vistos a seguir, ordenados da menor para a maior média possível:

```{r, echo=FALSE, warning=FALSE}
Allcomb = combn(x = pop, m = 5)
M_Allcomb = apply(Allcomb,2,mean)
M_Allcomb_round = round(M_Allcomb,1)
#matrix(M_Allcomb_round,nc = 14, byrow = T)
kable(matrix(M_Allcomb_round,nc = 14, byrow = T))
```

A menor e maior médias possíveis são `r min(M_Allcomb_round)` e `r max(M_Allcomb_round)` respectivamente. Estes valores são os mais distantes do parâmetro populacional ($\mu = `r mp`$) e ocorrem quando, **puramente ao acaso**, são amostrados os `r n` menores (`r sort(pop)[1:5]`) ou os `r n` maiores (`r sort(pop, dec = T)[1:5]`) elementos da população estatística. Estes casos extremos são **raros**. Em nosso exemplo, valores superiores a `r quantile(M_Allcomb_round, prob = 0.975)` ou inferiores a `r quantile(M_Allcomb_round, prob = 0.025)` são muito improváveis.


Podemos avaliar graficamente a distribuição das médias amostrais através de um histograma. A grande maioria das médias amostrais concentra-se na porção intermediária do gráfico entre estes limites. Por exemplo, somente `r round(mean(M_Allcomb_round >= quantile(M_Allcomb_round, prob = 0.975)) * 100,1)`% das observações estão acima de `r quantile(M_Allcomb_round, prob = 0.975)`. Da mesma forma, somente `r round(mean(M_Allcomb_round <= quantile(M_Allcomb_round, prob = 0.025)) * 100,1)`% das observações estão abaixo de `r quantile(M_Allcomb_round, prob = 0.025)`

```{r fig.align='center', echo=FALSE, fig.width=5, fig.height=5}
hist(M_Allcomb, breaks = seq(14, 38, by= 2), xlim = c(10, 40), main = "", xlab = "Distribuição das possíveis médias amostrais", 
     ylab = "Frequência observada", col = "grey")
legend(x = "topleft", legend = bquote("n = " ~ .(n)), bty = "n")
```


Se calcularmos a **média das médias** ($\overline{\overline{X}}$), ou seja, somarmos todos estes valores e dividirmos por `r CT`, o resultado será `r mean(M_Allcomb)`, que é exatamente o valor da média populacional $\mu$. Isto têm uma implicação  central em inferência estatística. Significa que a média amostral $\overline{X}$ é um estimador **acurado** (= **não-viciado**), pois tende a estimar corretamente o valor da média populacional $\mu$. Ou seja, o histograma acima está centrado ao redor de $\mu$, o que significa que **em média** uma amostra particular tem maior probabilidade de expressar um $\overline{X}$ próxima ao valor populacional. 

### Precisão
```{r, echo=FALSE}
n2 = 7
Allcomb7 = combn(x = pop, m = n2)
M_Allcomb7 = apply(Allcomb7,2,mean)
M_Allcomb7_round = round(M_Allcomb7,1)
CT2 = choose(N,n2)
```


Suponha agora que tomemos ao acaso amostras com $n = `r n2`$ desta mesma população. Existem ao todo:

$${{`r N`}\choose{`r n2`}} \frac{`r N`!}{(`r N`-`r n2`)! \times `r n2`!} = `r CT2`$$

amostras diferentes de tamanho $n = `r n2`$ que podem ser retiradas de uma população de tamanho  $n = `r N`$. Se tomarmos estas `r CT2` amostras e calcularmos suas respectivas médias amostrais, teremos os resultados abaixo:

```{r, warning=FALSE}
#matrix(M_Allcomb7_round,nc = 12, byrow = T)
kable(matrix(M_Allcomb7_round,nc = 12, byrow = T))
```


```{r fig.align='center', echo=FALSE, fig.width=5, fig.height=5}
hist(M_Allcomb7, breaks = seq(14, 38, by= 2), xlim = c(10, 40), main = "", xlab = "Distribuição das possíveis médias amostrais", 
     ylab = "Frequência observada", col = "grey")
legend(x = "topleft", legend = bquote("n = " ~ .(n2)), bty = "n")


ep = (sum((M_Allcomb - mean(M_Allcomb))^2)/CT)/ mean(M_Allcomb)
ep7 = (sum((M_Allcomb7 - mean(M_Allcomb7))^2)/CT2) / mean(M_Allcomb7)

```


Se compararmos os histogramas com $n = `r n`$ e $n = `r n2`$, veremos que as duas geram estimativas acuradas, pois $\overline{\overline{X}} = \mu$. No entando, o **intervalo de variação** é menor para amostras de tamanho $n = `r n2`$. Para esta figura, os valores estão mais concentrados ao redor da média. Portanto, à medida que aumenta o tamanhol amostral, diminui a disparsão das médias amostrais ao redor de $\mu$. Assim, para amostras grandes torna-se mais **improvável** obter uma média amostral distante da média populacional. Disemoz então que Conforme aumenta o tamanho amostral, aumenta a precisão do estimador.

### Erro padrão da média

A precisão de um estimador pode ser medida pelo **Erro padrão da média** ($\sigma_{\overline{X}}$) que pode ser calculado por:

$$\sigma_{\overline{X}} = \frac{\sigma}{\sqrt{n}}$$

O erro padrão da média é o desvio padrão de **todas** as médias amostrais que poderiam ser obtidas de uma amostra com tamanho $n$. Para nosso exemplo com $n = `r n`$, $\sigma_{\overline{X}}$ = `r round(ep,2)`, enquanto para $n = 7$, $\sigma_{\overline{X}}$ = `r round(ep7,2)`. Dizemos que o último exemplo provê um estimador **mais preciso**.

Como na vida real não temos como o obter **todas** as médias amostrais da população, não temos como saber com exatidão qual será o valor de $\sigma_{\overline{X}}$. No entanto, dado que temos uma amostra particular, podemos **estimá-lo** a partir de $\sigma_{\overline{X}}$ a partir de:

$$s_{\overline{X}} = \frac{s}{\sqrt{n}}$$

onde $s$ é o desvio padrão da amostra particular.

Após esta discussão, podemos representar os conceitos de precisão e acurária mostrados utilizando histogramas de distribuição de frequência para as médias amostrais. Vemos portanto que precisão e acurária têm relação respectivamente, com o **grau de variabilidade** das médias amostrais e com as **distâncias esperadas** de $\mu$.

```{r fig.cap = "Representação dos conceitos de precisão e acurácia. A linha vermelha tracejada representa a média populacional e os histogramas representam a distribuição de todas a médias amostrais com tamanho n desta população. A: estimativas acuradas e não-precisas; B: acuradas e precisas; C: não-acuradas e precisas; D: não-acuradas e não-precisas.", fig.align='center', echo=FALSE}
hisprecacu <- image_read_pdf("figs/Apostila_Estatistica_BICT-hist-prec-ac.pdf", density = 72)
grid.arrange(rasterGrob(hisprecacu), nrow = 1, ncol = 1)
```



```{r, echo=FALSE}
rm(list = ls())
```
