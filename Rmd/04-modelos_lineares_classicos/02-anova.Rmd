# Análise de variância de um fator {#anova}


```{r}
source('scriptsR/anova_sim.r')
```


A *Análise de Variância* (**ANOVA**) desenvolvida por <a href="https://en.wikipedia.org/wiki/Ronald_Fisher" target="_blank">R. A. Fisher</a> aplica-se à uma classe de desenho experimental em que a variável resposta $Y$ é *contínua* e a variável explanatória $X$ é *categórica* com $2$ ou mais níveis. A ANOVA permite testarmos a hipótese de que duas ou mais médias amostrais ($\overline{Y}_i$) possam ter sido obtidas de uma mesma população estatística com média $\mu$. Alternativamente, podemos concluir que as médias amostrais diferem umas das outras, de tal forma que devemos assumir que foram amostradas a partir de **diferentes populações estatísticas**, nas quais ao menos um $\mu_i$ seja diferente dos demais. Iremos denominar estas duas possibilidades de **hipótese estatísticas** sobre a relação entre as médias populacionais. 

## O modelo da ANOVA e as hipóteses estatísticas

O modelo pode ser representado por:

$$Y_{ij} = \mu + A_i + \epsilon_{ij}$$

onde $Y_{ij}$ é a variável resposta associada à observação $i$ do tratamento $j$, $\mu$ representa a média geral e $A_i$ o efeito do tratamento $i$. O termo $\epsilon_{ij}$ é denominado de **resíduo** (ou *erro*) associado a cada observação, que assumimos ter distribuição normal com média zero e variância constante.

$\epsilon \sim \mathcal{N}(0, \sigma^2)$

___

As hipóteses estatísticas no modelo de ANOVA são:

$H_0: \mu_1 = \mu_2 = \mu_3 =.... = \mu_k$ (HIPÓTESE NULA)

$H_a$: ao menos um par de médias é diferente (HIPÓTESE ALTERNATIVA)

___

A hipótese nula ($H_0$) define a ausência de diferenças entre as médias populacionais enquanto a hipótese alternativa ($H_a$) refere-se a qualquer possibilidade diferente de $H_0$. Se temos exatamente dois níveis em $X$, a comparação de médias pode ser feita por meio de um teste $t$. A ANOVA deve ser utilizada quando temos **mais** de dois níveis em $X$. Neste sentido, o teste $t$ é um caso particular da ANOVA.


## Partição da soma dos quadrados

A ANOVA consiste basicamente da **partição da soma dos quadrados** (Capítulo \@ref(biquantquali)) seguida da construção de um teste estatístico apropriado (o teste $F$) para verificar as plasibilidade de $H_0$. Apresentaremos aqui um exemplo simples descrito na figura e na tabela abaixo para descrever o ajuste da ANOVA.

```{r}
n = 5
B = c(b0 = 20, b1 = 0, b2 = 8, b3 = -8)
k = length(B) - 1
N = k * n 
dfe = anova_sim(B = B, seed = 1,
                 k = n) %>%
  #arrange(X, desc(Y)) %>% 
  mutate(Y = round(Y, 1),
         i = rep(1:n, times = k),
         j = rep(1:k, each = n)) %>% 
  mutate(ij = paste(i,j,sep = ''))

Ymeans = dfe %>% 
  group_by(X) %>% 
  summarise(medias = mean(Y))

Yg = mean(Ymeans$medias)

#dfe %>% kable()

plt_dfe = ggplot(dfe, aes(x = X, y = Y)) +
  geom_point() +
  theme_classic()
```


```{r, fig.align='center', fig.width=8, fig.height=5}
plt_dfe +
  gridExtra::tableGrob(dfe[,1:2])
```


Para deixarmos claro as notações que iremos adotar adiante neste capítulo vamos definir que:

+ Temos $k = `r k`$ grupos (`A`, `B` ou `C`) e para cada grupo $n =  `r n`$ observações. Denotamos por $n_{ij}$ o número de observações dentro de cada grupo, em que $i$ é a *i-ésima* observação ($i = 1$ a $`r n`$) do *j-ésimo* grupo ($j = 1$ a $`r k`$ - grupos `A` ao `C`). Neste exemplo, o número de observações em cada grupo é o mesmo ($n_1 = n_2 = n_3 = n$), de modo que o total de observações é dado por:

$N = k \times n = n_1 + n_2 + n_3 = `r N`$

+ A média de cada grupo será denotada por $\overline{Y}_j$, que neste exemplo são: $\overline{Y}_1 = `r Ymeans[1,2]`$ (grupo `A`), $\overline{Y}_2 = `r Ymeans[2,2]`$ (grupo `B`) e $\overline{Y}_3 = `r Ymeans[3,2]`$ (grupo `C`). Estas médias **estimam** as quantias $\mu_1$, $\mu_2$ e $\mu_3$ sobre as quais versam as hipóteses do modelo.

+ Vamos denotar por $\overline{\overline{Y}}$ a **Grande Média**, isto é, a média geral de todas as observações independente do grupo de origem e que é utilizada para **estimar** $\mu$.

$$\overline{\overline{Y}} = \sum_{j = 1}^{k}\sum_{i = 1}^{n}\frac{Y_{ij}}{N} = \frac{\overline{Y_1} + \overline{Y_2} + \overline{Y_3}}{3} = `r Yg`$$

Podemos agora observar estes elementos no gráfico de dispersão.

```{r}
Y1 = Ymeans$medias[1]
Y2 = Ymeans$medias[2]
Y3 = Ymeans$medias[3]
plt_dfe +
  theme(legend.position='none') +
  geom_hline(yintercept = Yg, alpha = 0.3, size = 2) +
  annotate('text', x = 3.4, 
           y = Yg + 1.5, 
           label = bquote(bar(bar(Y)) == .(Yg)),
           color = 'black', size = 3.5) +  
  annotate('text', x = as.numeric(dfe$X) + 0.1, 
           y = dfe$Y, label = paste('n',dfe$ij, sep = '_'),
           size = 3) +
  geom_point(data = Ymeans, 
            aes(x = X, y = medias, color = X),
            size = 5, alpha = 0.5) +
  annotate('text', x = as.numeric(Ymeans$X)[1] - 0.2, 
           y = Ymeans$medias[1] - 1.2, 
           label = bquote(bar(Y)[1] == .(Y1)),
           color = 'red', size = 3) +
  annotate('text', x = as.numeric(Ymeans$X)[2] - 0.25, 
           y = Ymeans$medias[2], 
           label = bquote(bar(Y)[2] == .(Y2)),
           color = 'green', size = 3) +
  annotate('text', x = as.numeric(Ymeans$X)[3] - 0.25, 
           y = Ymeans$medias[3], 
           label = bquote(bar(Y)[3] == .(Y3)),
           color = 'blue', size = 3)
```

Para ajustar o modelo de ANOVA a estes dados precisamos calcular $3$ quantias: i - a **Soma dos Quadrados Totais** ($SQ_{Total}$), ii - a **Soma dos Quadrados dos Tratamentos** $SQ_{Trat}$ e iii - a **Soma dos Quadrados dos Resíduos** $SQ_{Res}$.

i. **Soma dos Quadrados Totais** $SQ_{Total}$: mede as diferenças entre $Y_{ij}$ e $\overline{\overline{Y}}$. Temos nesta expressão o somatório dos desvios ao quadrado de todas as observações com relação à grande média **independente** do grupo de origem de cada observação.

$$SQ_{Total} = \sum_{j = 1}^{k}\sum_{i = 1}^{n}(Y_{ij} - \overline{\overline{Y}})^2$$

ii. **Soma dos Quadrados dos Tratamentos** $SQ_{Trat}$: mede as diferenças entre as **médias dos tratamentos** $\overline{Y}_j$ e $\overline{\overline{Y}}$, sendo portanto os desvios ao quadrado da média de cada tratamento subtraída da grande média. $SQ_{Trat}$ também é chamada de soma dos quadrados **entre grupos** ou **entre tratamentos**

$$SQ_{Trat} = \sum_{j = 1}^{k}\sum_{i = 1}^{n_{j}}(\overline{Y}_{j} - \overline{\overline{Y}})^2 = \sum_{j = 1}^{k}n_{j}(\overline{Y}_{j} - \overline{\overline{Y}})^2$$

iii. **Soma dos Quadrados dos Resíduos** $SQ_{Res}$: mede as diferenças entre cada observação $Y_{ij}$ e a média de seu próprio grupo $\overline{Y}_{j}$. $SQ_{Res}$ também é chamada de soma dos quadrados **dentro dos grupos** ou **dentro dos tratamentos**

$$SQ_{Res} = \sum_{j = 1}^{k}\sum_{i = 1}^{n_{j}}(Y_{ij} - \overline{Y}_{j})^2$$

### A característica aditiva das somas dos quadrados

A partição da soma dos quadrados consiste em decompor a **variação total** do experimento em uma parcela atribuída à variação **entre tratamentos** e outra parcela da variação **dentro dos tratamentos**. Isto é possível pois as somas dos quadrados definidas acima podem ser expressas de forma aditiva como:

___

$$SQ_{Total} = SQ_{Trat} + SQ_{Res}$$

___

> Deste modo, é possível demostrar que:
>
> $\sum_{j = 1}^{k}\sum_{i = 1}^{n}(Y_{ij} - \overline{\overline{Y}})^2 = \sum_{j = 1}^{k}n_{j}(Y_{j} - \overline{\overline{Y}})^2 + \sum_{j = 1}^{k}\sum_{i = 1}^{n}(Y_{ij} - \overline{Y}_{j})^2$


### Medindo a associação entre $Y$ e $X$

A característica aditiva das somas dos quadrados pode ser utilizada para mensurar o grau de dependência de $Y_{ij}$ com respeito aos diferentes tratamentos. Compare as duas figuras abaixo:

```{r}
n = 5
Bi = c(b0 = 20, b1 = 0, b2 = 1, b3 = -1)
k = length(B) - 1
N = k * n 
dfi = anova_sim(B = Bi, seed = 1,
                 k = n) %>%
  arrange(X, desc(Y)) %>% 
  mutate(Y = round(Y, 1),
         i = rep(1:n, times = k),
         j = rep(1:k, each = n)) %>% 
  mutate(ij = paste(i,j,sep = ''))

Ymeansi = dfi %>% 
  group_by(X) %>% 
  summarise(mediasi = mean(Y))

Ygi = mean(Ymeansi$mediasi)

plt_dfi = ggplot(dfi, aes(x = X, y = Y)) +
  geom_point() +
  theme_classic()

```


```{r, fig.align='center', fig.width=8, fig.height=4}
anova_dfe = anova(aov(Y ~ X, data = dfe))
SQ_Trat_dfe = round(anova_dfe$`Sum Sq`[1],1)
SQ_Res_dfe = round(anova_dfe$`Sum Sq`[2],1)
SQ_Total_dfe = SQ_Trat_dfe + SQ_Res_dfe

plt_diff = plt_dfe +
  geom_hline(yintercept = Yg, alpha = 0.3, size = 2) +
  annotate('text', x = 1, 
           y = 8, 
           label = bquote(bar(bar(Y)) == .(Yg)),
           color = 'black', size = 3.5) +
  geom_point(data = Ymeans, 
            aes(x = X, y = medias, color = X),
            size = 5, alpha = 0.5) +
  annotate('text', x = as.numeric(Ymeans$X)[1] - 0.2, 
           y = Ymeans$medias[1] - 1.2, 
           label = bquote(bar(Y)[1] == .(Y1)),
           color = 'red', size = 3) +
  annotate('text', x = as.numeric(Ymeans$X)[2] - 0.25, 
           y = Ymeans$medias[2], 
           label = bquote(bar(Y)[2] == .(Y2)),
           color = 'green', size = 3) +
  annotate('text', x = as.numeric(Ymeans$X)[3] - 0.25, 
           y = Ymeans$medias[3], 
           label = bquote(bar(Y)[3] == .(Y3)),
           color = 'blue', size = 3) +
  coord_cartesian(ylim = c(0,35)) +
  labs(title = expression(SQ[Total] == SQ[Trat] + SQ[Res]),
       subtitle = bquote(.(SQ_Total_dfe) == .(SQ_Trat_dfe) + .(SQ_Res_dfe))) +
  theme(legend.position='none',
        plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5))

anova_dfi = anova(aov(Y ~ X, data = dfi))
SQ_Trat_dfi = round(anova_dfi$`Sum Sq`[1],1)
SQ_Res_dfi = round(anova_dfi$`Sum Sq`[2],1)
SQ_Total_dfi = SQ_Trat_dfi + SQ_Res_dfi

Y1i = Ymeansi$mediasi[1]
Y2i = Ymeansi$mediasi[2]
Y3i = Ymeansi$mediasi[3]
plt_igu = plt_dfi +
  geom_hline(yintercept = Ygi, alpha = 0.3, size = 2) +
  annotate('text', x = 1, 
           y = 8, 
           label = bquote(bar(bar(Y)) == .(Ygi)),
           color = 'black', size = 3.5) +
  geom_point(data = Ymeansi, 
            aes(x = X, y = mediasi, color = X),
            size = 5, alpha = 0.5) +
  annotate('text', x = as.numeric(Ymeansi$X)[1] - 0.2, 
           y = Ymeansi$mediasi[1] - 1.2, 
           label = bquote(bar(Y)[1] == .(Y1i)),
           color = 'red', size = 3) +
  annotate('text', x = as.numeric(Ymeansi$X)[2] - 0.25, 
           y = Ymeansi$mediasi[2], 
           label = bquote(bar(Y)[2] == .(Y2i)),
           color = 'green', size = 3) +
  annotate('text', x = as.numeric(Ymeansi$X)[3] - 0.25, 
           y = Ymeansi$mediasi[3], 
           label = bquote(bar(Y)[3] == .(Y3i)),
           color = 'blue', size = 3) +
  coord_cartesian(ylim = c(0,35)) +
  labs(title = expression(SQ[Total] == SQ[Trat] + SQ[Res]),
       subtitle = bquote(.(SQ_Total_dfi) == .(SQ_Trat_dfi) + .(SQ_Res_dfi))) +
  theme(legend.position='none',
        plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5))

plt_igu | plt_diff
```

A soma dos quadrados dentro dos grupos é a mesma nas duas figuras ($SQ_{Res} = `r SQ_Res_dfi`$). No entanto, na figura da esquerda, em que as médias dos tratamentos são similares (e consequentemente próximas à grande média), a soma dos quadrados entre os tratamentos é muito menor ($SQ_{Trat}^{esquerda} = `r SQ_Trat_dfi`$) que na figura da direita, em que as médias dos tratamentos estão distantes entre si ($SQ_{Trat}^{direita} = `r SQ_Trat_dfe`$). É desta forma que a partição das somas dos quadrados nos permite diferenciar situações em que: i - a média dos grupos **depende** dos níveis do tratamento (figura da direita); de situações em que ii - a média **não depende** dos níveis do tratamento (figura da esquerda). 

## Quadrados médios e graus de liberdade

Para que os somatórios dos quadrados expressem uma medida de variação é necessário corriglos em função dos **graus de liberdade ($gl$)**, obtendo assim **Quadrados médios** dados abaixo:

1. Quadrado médio total ($QM_{Total}$)

$$QM_{Total} = \frac{SQ_{Total}}{gl_{Total}}$$

em que $gl_{Total} = N - 1$

2. Quadrado médio entre tratamentos ($QM_{Trat}$)

$$QM_{Trat} = \frac{SQ_{Trat}}{gl_{Trat}}$$

em que $gl_{Trat} = k - 1$

3. Quadrado médio dentro dos tratamentos ($QM_{Res}$)

$$QM_{Res} = \frac{SQ_{Res}}{gl_{Res}}$$

em que $gl_{Res} = N-k$

Assim como a soma dos quadrados, os graus de liberdade também têm característica aditiva.

$$gl_{Total} = gl_{Trat} + gl_{Res} = (k - 1) + (N - K) = N - 1$$

Os quadrados médios que são estimativas de variâncias. Compare por exemplo a expressão do $QM_{Total}$ com a fórmula da variância amostral ($s^2$) (Capítulo \@ref(variacao)) e verá que excetuando mudanças de notação, as expressões são essencialmente as mesmas.

## Estatística $F$ e teste de hipóteses

Uma vez que os quadrados médios são estimativas de variância, uma estatística de teste apropriada é:

$$F_{calculado} = \frac{QM_{Trat}}{QM_{Res}}$$

A estatística $F$ (ou razão-$F$) está associada à **distribuição de probabilidades $F$** e nos permite comparar a variância associada ao tratamento com a variância associada aos resíduos. Em mãos do valor de $F_{calculado}$, o teste de hipóteses é possível após a definição do **nível de significância** $\alpha$. 

### Nível de significância

Assim como discutimos nos testes $Z$ e $t$, o valor de $\alpha$ estabelece um limite de aceitação para $H_0$, isto é, um limite a partir do qual a estatística do teste se torna **tão extrema** que nos leva a assumir que $H_0$ é improvável, devendo portanto ser rejeitada em favor de $H_a$. Este passo é possível pois o valor de $F_{calculado}$ pode ser associado à distribuição $F$ de probabilidades, o que nos permite calcular a probabilidade:

$$P(F_{calculado}) \le \alpha$$

Para facilitar a notação denominaremos $P(F_{calculado})$ simplesmente de **valor de $p$** expresso em vermelho na figura abaixo:

> Se $p > \alpha$ --> **ACEITAMOS $H_0$**

> Se $p \le \alpha$ --> **REJEITAMOS $H_0$** (e assumimos $H_a$ como verdadeira)

```{r, fig.align='center', fig.height=4, fig.width=8}
glnon <- 5
glden <- 50

params = list(df1 = glnon, df2 = glden)
ylim = c(0,10)
pF = 0.90
lim <- qf(pF, df1 = glnon, df2 = glden)
dfF <- data.frame(x = seq(0.1,4, l = 100)) %>% 
  mutate(df = stats::df(x, df1 = glnon, df2 = glden))
Fcurve = ggplot(data = dfF, mapping = aes(x = x)) +
  stat_function(fun = stats::df, args = list(df1 = glnon, df2 = glden)) +
  geom_area(stat = "function", fun = stats::df, color = 1,
            args = params,
            fill = '#d14143',
            xlim = c(lim, ylim[2])) +
  theme_classic(base_size = 15) +
  xlab('X') + #ylab('Densidade de probabilidade') +
  theme(plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5, color = 'black')) +
  scale_x_continuous(name = 'F',
                     limits = range(dfF$x), labels = NULL, breaks = NULL) +
  scale_y_continuous(name = 'Densidade de probabilidade',
                     limits = c(0,0.8), labels = NULL, breaks = NULL) +
  annotate(geom = 'segment', x = lim - 0.0, xend = lim - 0.0,
           y = 0.5, yend = 0.2, color = 'gray', size = 2,
           arrow = arrow(length = unit(2, "mm"))) +
  annotate(geom = 'text', x = lim - 0.0, y = 0.55, size = 8,
           color = 'gray', label = bquote("F"["calculado"])) +
  annotate(geom = 'text', x = lim + 0.7, y = 0.15, size = 8,
           color = '#d14143', label = "Valor de p")

Fcurve
```

Tradicionalmente utiliza-se $\alpha = 0.05$. Neste caso, $H_0$ seria rejeitada somente de $p \le 0.05$. Algumas área da medicina por eoutro lado, são tradicionais por utilizar valores de $\alpha = 0.01$, o que torna o experimento menos sujeito ao **erro do tipo I** (Capítulo \@ref(th)). Portanto, outros valores de $\alpha$ diferentes de $0.05$ podem ser escolhidos. O fundamental é que esta decisão, isto é, sobre o nível de significância $\alpha$ a ser adotado, seja feita **previamente** à obtenção dos dados.  

## Um exemplo de ANOVA

Vamos exemplificar o passo-a-passo de uma ANOVA utilizandocom nosso exemplo fictício. /o primeiro passo é definir as hipóteses estatpisticas e o nível de significância:

___


$H_0: \mu_1 = \mu_2 = \mu_3$

$H_a$: ao menos um $\mu$ é diferente

$\alpha = 0.05$

___


Utilizando os tados da tabela abaixo podemos obetr todas as quantias necessárias para o cálculo da ANOVA, isto é, os somatórios dos quadrados, os graus de liberdade,os quadraos médios e finalmente o valor de $F_{calculado}$

```{r}
Tab = data.frame(dfe[,1:2])
```


```{r}
anova_ex = anova(aov(Y ~ X, data = Tab))
kableExtra::kable(Tab)
```

___

**1. Somatórios dos quadrados**

$SQ_{Trat} = \sum_{j = 1}^{k}\sum_{i = 1}^{n_{j}}(\overline{Y}_{j} - \overline{\overline{Y}})^2 = `r anova_ex[[2]][1]`$

$SQ_{Res} = \sum_{j = 1}^{k}\sum_{i = 1}^{n_{j}}(Y_{ij} - \overline{Y}_{j})^2 = `r anova_ex[[2]][2]`$

___

**2. Graus de liberdade**

$gl_{Trat} = k - 1 = `r anova_ex[[1]][1]`$

$gl_{Res} = N-k = `r anova_ex[[1]][2]`$


___

**3. Quadrados médios**

$QM_{Trat} = \frac{SQ_{Trat}}{gl_{Trat}} = `r anova_ex[[3]][1]`$


$QM_{Res} = \frac{SQ_{Res}}{gl_{Res}} = `r anova_ex[[3]][2]`$

___

**4. Estatística $F$**

$F_{calculado} = \frac{QM_{Trat}}{QM_{Res}} = `r anova_ex[[4]][1]`$

___

**5. Tabela da ANOVA**

Estas quantias são tradicionalmente expressas em uma **Tabela de ANOVA** conforme abaixo:

```{r}
kableExtra::kable(anova_ex)
```

em que:

`Df`: graus de liberdade

`Sum Sq`: soma dos quadrados

`Mean Sq`: quadrados médios

`F value`: valor de $F_{calculado}$

`Pr(>F)`: valor de p

A primeira linha refere-se aos valores associados aos tratamentos e a segunda linha aos resíduos. Note que o cômputo de $SQ_{Total}$, $gl_{Total}$ e $QM_{Total}$ não é realmente necessário.

___

O valor de $p = `r anova_ex[[4]][1]`$ mostrado na tabela acima é aquele referência à área na distribuição $F$ que fica acima de $F_{calculado}$. Poderíamos tentar observar representar este valor visualmente na distribuição $F$, mas ele é tão pequeno, que a área em vermelho sequer aparece na figura.

```{r, fig.align='center', fig.height=4, fig.width=8}
glnon <- anova_ex[[1]][1]
glden <- anova_ex[[1]][2]

params = list(df1 = glnon, df2 = glden)
ylim = c(0,10)
pF = 1 - anova_ex[[5]][1]
lim <- qf(pF, df1 = glnon, df2 = glden)
dfF <- data.frame(x = seq(0.1,13, l = 100)) %>% 
  mutate(df = stats::df(x, df1 = glnon, df2 = glden))
Fcurve = ggplot(data = dfF, mapping = aes(x = x)) +
  stat_function(fun = stats::df, args = list(df1 = glnon, df2 = glden)) +
  geom_area(stat = "function", fun = stats::df, color = 1,
            args = params,
            fill = '#d14143',
            xlim = c(lim, ylim[2])) +
  theme_classic(base_size = 15) +
  xlab('X') + #ylab('Densidade de probabilidade') +
  theme(plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5, color = 'black')) +
  scale_x_continuous(name = 'F',
                      breaks = seq(0,13, by = 1)) +
  scale_y_continuous(name = 'Densidade de probabilidade',
                     breaks = seq(0,1, by = 0.1)) +
  annotate(geom = 'segment', x = anova_ex[[4]][1], xend = anova_ex[[4]][1],
           y = 0.5, yend = 0.02, color = 'gray', size = 2,
           arrow = arrow(length = unit(2, "mm"))) +
  annotate(geom = 'text', x = anova_ex[[4]][1], y = 0.55, size = 8,
           color = 'gray', label = bquote("F"["calculado"])) +
  annotate(geom = 'text', x = lim + 1.2, y = 0.03, size = 6,
           color = '#d14143', label = "Valor de p")

Fcurve
```

Como conclusão temos que $p \le \alpha$ nos leva a **REJEITAR $H_0$**, pois $F_{calculado}$ é muito extremo para ser resultante da hipótese nula. Neste caso, assumimos que a $H_a$ é mais condizente com a estrutura dos dados, de modo que os tratamentos devem ser provenientes de populações estatísticas com diferentes médias $\mu$.

## Testes a *posteriori* de comparação de médias

Tendo rejeitado $H_0$ concluímos que ao menos 1 par médias é diferente entre si, saber qual(is). Isto nos leva a buscar por um teste que permita fazer comparações **par-a-par**. Os testes a *posteriori* são uma alternativa.

Entre os diferentes testes a *posteriori* na literatura discutiremos o <a href="https://en.wikipedia.org/wiki/Tukey%27s_range_test" target="_blank">teste de Tukey</a>, em que o objetivo é estabelecer uma *Diferença Honesta Significativa* (*DHS*) entre um dado par de médias. Esta diferença pode ser calculada por:

$$DHS_{12} = q\sqrt{\left(\frac{1}{n_1} + \frac{1}{n_2}\right)QM_{Res}}$$

onde:

$q$: é um valor retirado de uma **tabela estatística da distribuição de amplitude normalizada** (*studentized range q table*). Para um dado $\alpha$, o valor desejado de $q$ é encontrado cruzando a linha contento o número de grupos $k$ tratamentos do experimento com a linha contendo os graus de liberdade do resíduo ($gl_{Res}$). Veja um exemplo desta tabela no link: <a href="https://www.real-statistics.com/statistics-tables/studentized-range-q-table/" target="_blank">Studentized Range q Table</a>;

$QM_{Res}$: é quadrado médio do resíduo obtido na ANOVA, e;

$n_1$, $n_2$: os tamanhos amostrais de cada grupo envolvido na comparação.

Para um dado nível de significância $\alpha$, a $DHS$ irá depender basicamente da variação residual do modelo de ANOVA e dos tamanhos amostrais de cada grupo. Em um experimento **balanceado**, isto é, onde $n_1 = n_2 = \cdots = n_k = n$, a diferença mínima para que um par de médias seja cosiderado diferente é sempre a mesma.

Em nosso exemplo, a $DHS$ com $\alpha = 0.05$ será:

```{r}
q =  qtukey(p = 0.95, nmeans = 3, df = anova_ex[[1]][2])
DHS = q * sqrt((1/n + 1/n)*anova_ex[[3]][2])
```

$DHS =  `r round(q,3)`\sqrt{\left(\frac{1}{`r n`} + \frac{1}{`r n`}\right)`r anova_ex[[3]][2]`} = `r round(DHS, 3)`$

Assim, qualquer diferença entre pares de médias maior ou igual a $`r round(DHS, 3)`$ será considerada **estatisticamente significativa**, nos levando a concluir que aqueles grupos têm médias populacionais distintas.

Em nosso exemplo, as médias dos grupos foram:

+ Grupo `A`: $\overline{Y}_A = `r Ymeans[1,2]`$

+ Grupo `B`: $\overline{Y}_B = `r Ymeans[2,2]`$

+ Grupo `C`: $\overline{Y}_C = `r Ymeans[3,2]`$

E as diferenças ($\overline{Y}_{maior} - \overline{Y}_{menor}$) entre elas:

```{r}
Ymean = tapply(Tab$Y, Tab$X, mean)
Ymean_D = as.matrix(dist(Ymean))
Ymean_D[upper.tri(Ymean_D)] = NA
kableExtra::kable(Ymean_D)
```

Das três comparações possíveis, somente a comparação entre os grupos `B` e `C` ($\overline{Y}_B - \overline{Y}_C = `r Ymean_D[3,2]`$) foi maior que o limite estabelecido pelo teste de Tukey. Desta forma, concluímos que a ANOVA foi significativa e que somente os grupos `B` e `C` diferem entre si.

## Rodando a ANOVA no R

Considere que a tabela em nosso exemplo está no objeto `Tab`. A ANOVA no R é feita com o comando `aov`.

```{r, echo = TRUE}
ajuste = aov(Y ~ X, data  = Tab)
ajuste
```

> A notação `Y ~ X` será muito utilizada nesta seção sobre modelos lineares e lê-se como **$Y$ é função de $X$**. 

O comando acima fez os cálculos da ANOVA, isto é, computou as somas dos quadrados, os graus de liberdade, os quadrados médios, o $F_{calculado}$ e o valor de $p$. Para visualizarmos a tabela da ANOVA fazemos:

```{r echo = TRUE}
anova(ajuste)
```

Note que os resultados coincidem com o que apresentamos anteriormente. Como o valor de $p$ foi menor que $\alpha = 0.05$, concluimos que a ANOVA foi significativa, isto é, indicou que ao menos um par de médias difere ente si. Podemos fazer o teste a *posteriori* de Tukey com o comando:

```{r}
alfa = 0.05
TukeyHSD(ajuste, conf.level = 1-alfa)
```

O resultado apresenta todas as comparações possíveis entre os grupos, mostrando as diferenças de médias, seus intervalos de confiança a $95\%$ e os valores de $p$, indicando quais destas diferenças são significativas, isto é, $p \le \alpha$. Estes resultados nos permitem concluir novamente que somente o par `C-B` difere entre si, pois  `p adj < 0.05`.

Um gráfico facilita a visualização das comparações, sobretudo em situações com muitos pares de médias envolvidos:

```{r}
plot(TukeyHSD(ajuste))
```

Neste gráfico, as comparações em que o intervalo de confiança **não inclui o zero**, são consideradas significativas. Novamente, vemos que somente o grupo `C-B` tem médias estatisticamente diferentes.

## Pressupostos da ANOVA

Os pressupostos da ANOVA são:

1. Os observação são independentes e;

2. A variância dos resíduos é homogênea e;

3. Os resíduos têm distribuição normal com média $0$ e variância $\sigma^2$.

Vamos inicialmente testar o pressuposto de homogeneidade de variâncias com um teste $F$. 

```{r, echo = F}
v = tapply(Tab$Y, Tab$X, var)
var_max = max(v)
var_min = min(v)

```

```{r, echo = T, eval = F}
Tab %>% group_by(X) %>% 
  summarise(Var = var(Y))
```

Note que a maior variância é $`r var_max`$ e a menor $`r var_min`$.

O teste $F$ consiste em dividir a maior variância pela menor:

```{r}
var.test(Tab$Y[Tab$X == "C"], Tab$Y[Tab$X == "B"])
```

A maior variância foi `r round(var_max/var_min, 2)` vezes maior que a menor variância e o test F sugere que esta diferença é **não-significativa** a $5\%$  ($p < 0.05$). Isto indica que as variâncias são homogêneas.

A verificação visual de que as variâncias são homogêneas pode também ser inspecionada pelo **gráfico de resíduos**:

```{r}
plot(rstudent(ajuste) ~ fitted(ajuste), pch = 16)
abline(h = 0, col = 2)
```

Em seguida avaliamos o histograma dos resíduos e aplicamos um teste de normalidade (ex. teste de Shapiro-Wilk) para verificar se o pressuposto de normalidade pode ser aceito.

```{r}
hist(rstudent(ajuste), breaks = 10)
shapiro.test(rstudent(ajuste))
```

Neste caso, o valor de $p > 0.05$ indica não haver desvio da normalidade.

